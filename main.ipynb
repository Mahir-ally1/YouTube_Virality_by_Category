{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d324fa9-ec54-4e3a-a424-0605d842209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Libraries\n",
    "!pip install --upgrade google-api-python-client --quiet\n",
    "import json\n",
    "import googleapiclient\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1bb6fc-04e7-40fd-ba01-b7b7d626f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path_to_json = \"info.json\"\n",
    "\n",
    "with open(path_to_json, \"r\") as handler:\n",
    "    info = json.load(handler)\n",
    "\n",
    "API_KEY = info[\"API_KEY\"]\n",
    "!pip install --upgrade google-api-python-client --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad01603-136b-4fac-8b08-73a2f70ddd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea623fac-a119-432d-b01c-06b3427401f8",
   "metadata": {},
   "source": [
    "## In this section, we collect data from a wide variety of the channels. The output of this would be a dataframe with the following structure - \n",
    "\n",
    "<!-- ##### { \n",
    "'channel_name' : ,\n",
    "'video_id' : ,\n",
    "'video_like' :,\n",
    "'video_comments' :\n",
    "'video_category' :\n",
    "} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b0c1ae-fbb4-437c-a861-94e475cc605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos extracted from Vsauce are:  5\n",
      "The videos extracted from CNN are:  5\n",
      "The videos extracted from moneycontrol are:  5\n"
     ]
    }
   ],
   "source": [
    "# Video & Metrics Calculation\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "def download_statistics(username, limit=10, api_key=None):\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "    part=\"contentDetails\",\n",
    "    forUsername=username\n",
    "    )\n",
    "    \n",
    "    res = request.execute()\n",
    "    uploads_playlist_id = res[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "    videos_info = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet\",\n",
    "        playlistId = uploads_playlist_id\n",
    "        # YOUR SOLUTION\n",
    "    )\n",
    "    \n",
    "    res = request.execute()\n",
    "    \n",
    "    page_token = res['nextPageToken'] if res['nextPageToken'] else \"\"\n",
    "    for v in res[\"items\"]:\n",
    "        video_id = v['snippet']['resourceId']['videoId']\n",
    "            \n",
    "        # Get video views count\n",
    "        stats_request = youtube.videos().list(\n",
    "            part=\"statistics\",\n",
    "            id=video_id\n",
    "        )\n",
    "        stats_res = stats_request.execute()\n",
    "            \n",
    "        # Check if statistics are available for the video\n",
    "        if stats_res['items']:\n",
    "            statistics = stats_res['items'][0]['statistics']\n",
    "            view_count = int(statistics.get('viewCount', 0))\n",
    "            like_count = int(statistics.get('likeCount',0))\n",
    "            comment_count = int(statistics.get('commentCount',0))\n",
    "        else:\n",
    "            view_count = like_count = comment_count = 0\n",
    "    \n",
    "        dict_vid = {\n",
    "            'channel_name': v['snippet']['channelTitle'],\n",
    "            'video_id': video_id,\n",
    "            'video_title': v['snippet']['title'],\n",
    "            'video_description': v['snippet']['description'],\n",
    "            'video_published_at': v['snippet']['publishedAt'],\n",
    "            'video_view_count': view_count,\n",
    "            'video_like_count': like_count,\n",
    "            'video_comment_count': comment_count\n",
    "        }\n",
    "        videos_info.append(dict_vid)\n",
    "\n",
    "    while page_token and len(videos_info) < limit: # Limiting the number of API calls using the videos_info as the daily limit is exceeding otherwise\n",
    "        request = youtube.playlistItems().list(\n",
    "        part=\"snippet\",\n",
    "        playlistId = uploads_playlist_id,\n",
    "        pageToken = page_token\n",
    "    )\n",
    "        res = request.execute()\n",
    "        page_token = res['nextPageToken'] if res['nextPageToken'] else \"\"\n",
    "    \n",
    "        for v in res[\"items\"]:\n",
    "            video_id = v['snippet']['resourceId']['videoId']\n",
    "            \n",
    "            # Get video video views count\n",
    "            stats_request = youtube.videos().list(\n",
    "                part=\"statistics\",\n",
    "                id=video_id\n",
    "            )\n",
    "            stats_res = stats_request.execute()\n",
    "            \n",
    "            # Check if statistics are available for the video\n",
    "            if stats_res['items']:\n",
    "                statistics = stats_res['items'][0]['statistics']\n",
    "                view_count = int(statistics.get('viewCount', 0))\n",
    "                like_count = int(statistics.get('likeCount',0))\n",
    "                comment_count = int(statistics.get('commentCount',0))\n",
    "            else:\n",
    "                view_count = like_count = comment_count = 0\n",
    "    \n",
    "            dict_vid = {\n",
    "                'channel_name': v['snippet']['channelTitle'],\n",
    "                'video_id': video_id,\n",
    "                'video_title': v['snippet']['title'],\n",
    "                'video_description': v['snippet']['description'],\n",
    "                'video_published_at': v['snippet']['publishedAt'],\n",
    "                'video_view_count': view_count,\n",
    "                'video_like_count': like_count,\n",
    "                'video_comment_count': comment_count\n",
    "            }\n",
    "            videos_info.append(dict_vid)\n",
    "    print(f\"The videos extracted from {username} are: \", len(videos_info))\n",
    "    return videos_info\n",
    "    \n",
    "\n",
    "API_KEY = API_KEY\n",
    "youtube_channel_1 = [\n",
    "    \"Vsauce\",\n",
    "    \"CNN\",\n",
    "    \"moneycontrol\",   \n",
    "]\n",
    "\n",
    "export_data = []\n",
    "for channel in youtube_channel_1:\n",
    "    export_data.extend(download_statistics(channel, limit=5, api_key=API_KEY))\n",
    "\n",
    "current_datetime = datetime.datetime.now()\n",
    "transcript_data_path = f\"data/transcript_data_{str(current_datetime)}.csv\"\n",
    "#print('The number of total extracted videos is:', len(export_data))\n",
    "#print(json.dumps(export_data,indent=2))\n",
    "pd.DataFrame(export_data).to_csv(transcript_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea9f33e-1f13-43de-95f3-182c2d8ae5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api --quiet\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2bb604-cae6-4a41-bb39-c095752b0398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ynGb9FcH5ME\n",
      "pnt-GwDokts\n",
      "r734u7g80Zw\n",
      "UuqBFnhoqhM\n",
      "F9QS_qbeNLU\n",
      "iWsFdmCQV74\n",
      "k6iYXVvKxoI\n",
      "UuY7PMpYjLE\n",
      "prsWw4q8XOM\n",
      "3HGwjgYQgCU\n",
      "hQyPOJ641vQ\n",
      "ADO095Z3V7M\n",
      "H3XoUT7tLoI\n",
      "ePiTTJ-8ULc\n",
      "KI0VAK-29fE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_published_at</th>\n",
       "      <th>video_view_count</th>\n",
       "      <th>video_like_count</th>\n",
       "      <th>video_comment_count</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Vsauce</td>\n",
       "      <td>ynGb9FcH5ME</td>\n",
       "      <td>Okay, Here's The 'Reindeer'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01T14:41:41Z</td>\n",
       "      <td>4262571</td>\n",
       "      <td>364254</td>\n",
       "      <td>5338</td>\n",
       "      <td>I will show you the reindeer it's pretty simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vsauce</td>\n",
       "      <td>pnt-GwDokts</td>\n",
       "      <td>The Pioneer Puzzle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-30T14:28:54Z</td>\n",
       "      <td>3702468</td>\n",
       "      <td>354024</td>\n",
       "      <td>3218</td>\n",
       "      <td>the Wonder block or Pioneer puzzle a set of do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vsauce</td>\n",
       "      <td>r734u7g80Zw</td>\n",
       "      <td>It's Time To Rename Uranus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-26T00:04:32Z</td>\n",
       "      <td>3936739</td>\n",
       "      <td>489296</td>\n",
       "      <td>14291</td>\n",
       "      <td>Merry Christmas it's time to rename Uranus the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Vsauce</td>\n",
       "      <td>UuqBFnhoqhM</td>\n",
       "      <td>THE COMPLETE LIST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-22T19:44:05Z</td>\n",
       "      <td>973738</td>\n",
       "      <td>66307</td>\n",
       "      <td>794</td>\n",
       "      <td>okay I've got some exciting news about the Vsa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Vsauce</td>\n",
       "      <td>F9QS_qbeNLU</td>\n",
       "      <td>The Most-Photographed Toilet In New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-21T01:46:48Z</td>\n",
       "      <td>2800996</td>\n",
       "      <td>224193</td>\n",
       "      <td>3082</td>\n",
       "      <td>come with me as I poop in New Zealand's most p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 channel_name     video_id  \\\n",
       "0           0       Vsauce  ynGb9FcH5ME   \n",
       "1           1       Vsauce  pnt-GwDokts   \n",
       "2           2       Vsauce  r734u7g80Zw   \n",
       "3           3       Vsauce  UuqBFnhoqhM   \n",
       "4           4       Vsauce  F9QS_qbeNLU   \n",
       "\n",
       "                                   video_title video_description  \\\n",
       "0                  Okay, Here's The 'Reindeer'               NaN   \n",
       "1                           The Pioneer Puzzle               NaN   \n",
       "2                   It's Time To Rename Uranus               NaN   \n",
       "3                            THE COMPLETE LIST               NaN   \n",
       "4  The Most-Photographed Toilet In New Zealand               NaN   \n",
       "\n",
       "     video_published_at  video_view_count  video_like_count  \\\n",
       "0  2024-01-01T14:41:41Z           4262571            364254   \n",
       "1  2023-12-30T14:28:54Z           3702468            354024   \n",
       "2  2023-12-26T00:04:32Z           3936739            489296   \n",
       "3  2023-12-22T19:44:05Z            973738             66307   \n",
       "4  2023-12-21T01:46:48Z           2800996            224193   \n",
       "\n",
       "   video_comment_count                                         transcript  \n",
       "0                 5338  I will show you the reindeer it's pretty simpl...  \n",
       "1                 3218  the Wonder block or Pioneer puzzle a set of do...  \n",
       "2                14291  Merry Christmas it's time to rename Uranus the...  \n",
       "3                  794  okay I've got some exciting news about the Vsa...  \n",
       "4                 3082  come with me as I poop in New Zealand's most p...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transcript download\n",
    "\n",
    "transcript_data = pd.read_csv(transcript_data_path)\n",
    "\n",
    "# Function to get transcript for a given video_id\n",
    "def get_transcript(video_id):\n",
    "    print(video_id)\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return ' '.join([entry['text'] for entry in transcript])\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        return ''\n",
    "\n",
    "# Apply the function to create a new 'transcript' column\n",
    "transcript_data['transcript'] = transcript_data['video_id'].apply(get_transcript)\n",
    "transcript_data.to_csv(transcript_data_path)\n",
    "transcript_data.head()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85dc239f-a7e1-4a3f-afa1-07bb77c88cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content Categorization\n",
    "# https://cloud.google.com/natural-language/docs/classifying-text#language-classify-content-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31b85f-4dc8-4430-b562-e70ef3d29a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184885e-0794-4b81-ae54-70130a9a2a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
